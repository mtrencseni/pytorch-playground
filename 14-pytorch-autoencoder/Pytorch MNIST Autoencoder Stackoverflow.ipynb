{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss: 0.6444\n",
      "epoch [2/100], loss: 0.5433\n",
      "epoch [3/100], loss: 0.4430\n",
      "epoch [4/100], loss: 0.4201\n",
      "epoch [5/100], loss: 0.4021\n",
      "epoch [6/100], loss: 0.4328\n",
      "epoch [7/100], loss: 0.4684\n",
      "epoch [8/100], loss: 0.3794\n",
      "epoch [9/100], loss: 0.3339\n",
      "epoch [10/100], loss: 0.3466\n",
      "epoch [11/100], loss: 0.3647\n",
      "epoch [12/100], loss: 0.4495\n",
      "epoch [13/100], loss: 0.4239\n",
      "epoch [14/100], loss: 0.3173\n",
      "epoch [15/100], loss: 0.3306\n",
      "epoch [16/100], loss: 0.4652\n",
      "epoch [17/100], loss: 0.4754\n",
      "epoch [18/100], loss: 0.4985\n",
      "epoch [19/100], loss: 0.4303\n",
      "epoch [20/100], loss: 0.3761\n",
      "epoch [21/100], loss: 0.4724\n",
      "epoch [22/100], loss: 0.4677\n",
      "epoch [23/100], loss: 0.4720\n",
      "epoch [24/100], loss: 0.3533\n",
      "epoch [25/100], loss: 0.4324\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "trainset = tv.datasets.MNIST(root='./data',  train=True, download=True, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # 28 x 28\n",
    "            nn.Conv2d(1, 4, kernel_size=5),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            # 4 x 24 x 24\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(4, 8, kernel_size=5),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            # 8 x 20 x 20 = 3200\n",
    "            nn.ReLU(True),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3200, 32)\n",
    "            )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 400),\n",
    "            nn.ReLU(True),\n",
    "            # 400\n",
    "            nn.Unflatten(1, (1, 20, 20)),\n",
    "            # 20 x 20\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            nn.ConvTranspose2d(1, 10, kernel_size=5),\n",
    "            # 24 x 24\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            nn.ConvTranspose2d(10, 1, kernel_size=5)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        out = self.decoder(out)\n",
    "        return out\n",
    "\n",
    "model = Autoencoder().to(device)\n",
    "distance = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        img, _ = data\n",
    "        img = img.to(device)\n",
    "        output = model(img)\n",
    "        loss = distance(output, img)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('epoch [{}/{}], loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 27.   0.  10.   0.   0. 705. 225.  12.   0.   1.]\n",
      " [  1.   1.   0.   0.   0.   0. 414.   0. 650.  69.]\n",
      " [119.   1.   2.   1.  25.  28. 826.   5.  19.   6.]\n",
      " [217.   0.   1.   0.   0. 193. 366.   1.   9. 223.]\n",
      " [ 98.  11.  12.   0.   6.   0. 677.   4.   0. 174.]\n",
      " [ 49.   0.   2.   0.   0. 131. 591.   3.   1. 115.]\n",
      " [118.   0.   0.   0.  95.  24. 678.  40.   1.   2.]\n",
      " [ 40.  89. 321.   0.   0.   8. 282.   0.   3. 285.]\n",
      " [  8.   0.   0.   0.   0.   9. 919.   0.   0.  38.]\n",
      " [ 28.   4.  19.   0.   5.   2. 684.   1.   0. 266.]]\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "confusion_matrix = np.zeros((10, 10))\n",
    "\n",
    "batch_size = 20*1000\n",
    "\n",
    "testset = tv.datasets.MNIST(root='./data',  train=False, download=True, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "for data in dataloader:\n",
    "    imgs, labels = data\n",
    "    imgs = Variable(imgs).cpu()\n",
    "    encs = model.encoder(imgs).detach().numpy()\n",
    "    for i in range(len(encs)):\n",
    "        predicted = np.argmax(encs[i])\n",
    "        actual = labels[i]\n",
    "        confusion_matrix[actual][predicted] += 1\n",
    "print(confusion_matrix)\n",
    "print(int(confusion_matrix.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual label 0 most likely activates on neuron 5 (71%)\n",
      "Actual label 1 most likely activates on neuron 8 (57%)\n",
      "Actual label 2 most likely activates on neuron 6 (80%)\n",
      "Actual label 3 most likely activates on neuron 6 (36%)\n",
      "Actual label 4 most likely activates on neuron 6 (68%)\n",
      "Actual label 5 most likely activates on neuron 6 (66%)\n",
      "Actual label 6 most likely activates on neuron 6 (70%)\n",
      "Actual label 7 most likely activates on neuron 2 (31%)\n",
      "Actual label 8 most likely activates on neuron 6 (94%)\n",
      "Actual label 9 most likely activates on neuron 6 (67%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({2, 5, 6, 8}, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_neurons = set()\n",
    "for actual in range(10):\n",
    "    predicted = np.argmax(confusion_matrix[actual])\n",
    "    pct = 100 * confusion_matrix[actual][predicted] / np.sum(confusion_matrix[actual])\n",
    "    print('Actual label %d most likely activates on neuron %d (%d%%)' % (actual, predicted, pct))\n",
    "    active_neurons.add(predicted)\n",
    "active_neurons, len(active_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
